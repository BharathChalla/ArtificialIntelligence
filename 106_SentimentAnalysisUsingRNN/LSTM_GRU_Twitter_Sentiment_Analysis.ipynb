{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Twitter Sentiment Analysis Using RNN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!nvidia-smi"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PCofMWa9XLRD",
    "outputId": "1dca2cbc-68ec-45a3-8c44-4bd110dc4f0f"
   },
   "execution_count": 1,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mon Nov 21 17:06:31 2022       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 515.65.01    Driver Version: 515.65.01    CUDA Version: 11.7     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA A40          On   | 00000000:4B:00.0 Off |                    0 |\n",
      "|  0%   59C    P0    92W / 300W |      4MiB / 46068MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      2203      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import string\n",
    "from collections import Counter\n",
    "from string import punctuation\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Use GPU if available\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using: {device}\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JwFPxAWwbvGq",
    "outputId": "2fbc135c-11b8-47f9-a9bf-e74b01ce8bc7"
   },
   "execution_count": 2,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Using: cuda:0\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## IMDB Movies Review Dataset"
   ],
   "metadata": {
    "id": "o_WWAXYSewmY"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# !wget -O training.1600000.processed.noemoticon.csv https://utdallas.app.box.com/shared/static/kw4a5e3lk00731kyho8kd2c6hwlr0t2m/\n",
    "# !curl -L \"https://utdallas.app.box.com/shared/static/kw4a5e3lk00731kyho8kd2c6hwlr0t2m/\" --output training.1600000.processed.noemoticon.csv"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dV1GiKWCrQFM",
    "outputId": "7b51e6ef-90dd-4992-d2b8-74e0c7cf1576"
   },
   "execution_count": 3,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "--2022-11-21 17:06:33--  https://utdallas.app.box.com/shared/static/kw4a5e3lk00731kyho8kd2c6hwlr0t2m/\r\n",
      "Resolving utdallas.app.box.com (utdallas.app.box.com)... 74.112.186.144\r\n",
      "Connecting to utdallas.app.box.com (utdallas.app.box.com)|74.112.186.144|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: /public/static/kw4a5e3lk00731kyho8kd2c6hwlr0t2m [following]\n",
      "--2022-11-21 17:06:33--  https://utdallas.app.box.com/public/static/kw4a5e3lk00731kyho8kd2c6hwlr0t2m\n",
      "Reusing existing connection to utdallas.app.box.com:443.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://dl2.boxcloud.com/d/1/b1!YQgULKDM8oWKm58BK2YhkMIxaRccIY8LhufI_t57opZ3iV3uk5Fo3TdkNOwomjZium_KTvKbRn_iLLNt1lM4qVmyS-PqBfq7MGoV4W_vCkkDFqJvVO-nZ3O5agsEIlEyur_CP7bgBcYlkhhBmpxntLeJPJmXzZIbGbhrWqxTi59515k0tfePbBD3fLytm1CegAKYsPFSid7toosS2i9mvTDdCiwPD4gYLF_BCbBJS6b1tmSjYarPOVgxgp33_ilKNoZ7v5FFvYEP6Rnb8MXQKMa57m0oRYxoXk5ysOqA0FFcuaj-AAwVKy-UhWgtiXZ8rK0FxvIMgD3QB3J_aSTMOVg1Vt-wVoW77Y7mFRg2XIGGi-uROle6mYI4chAuks8RaEaYgPQ4eOWKVau5-kfO0Q2p3-k6-SQ0KdxGJdqjsh9TZjlx_z74K9gdtKMPY1NRiVz1CS_oC2YBnzeRCPIjuUR_ld_Fyon3CcUPPCXp9he2rA2TU3spoyFJW0sQO_0L8ekjCk2vxY6V6RwXGNfMKA6f4ZhWo4AxGkLZdtybQgs_0PrP-excjYLXKD9LoAyqe3VPGQkjAGWL0ZgD2arRxmZHhNQXEu1v84Zva1LIN52wmk-EvRygpJszVhAVToRceFL_nzD30uU3QRmP8v7PoTMxOx18VyrVSRReAIgdRWY23VcNaIOeYfmOE2TWrlhZQPEHrlM5HeMln7A_H7Rh-mXB4Ei4oSyesMlXxOABE4165aVFAxP2pGhZM22WgPQneUL85WxNtjMp5ZIZUIWuY5mFVf-bMsyasbhPnuLj10aTHcIY64J-wj7fyT4yFhuR_qZQlDal5Z6mRRTcV_nLJDfNzpc8MamG-U23VJhxM_Go4yvIldEnOOdhZSWX9TY1OMPAGolC5UR9M7AJoh4Ob80qug8ONKey8zm-9HjCv6eCajO1K9MT-mNl6U-jK5YPfnOZgEB2_ea31Ov4lw79zvgIMxqfidKsEiimM3g_wk0POOKcIHqDTTbv0kk8BCHvcnUn2mbsz4K38m-z7Qd4NOGcuP9Me-UcdRDP6uOWmdIbfYaSgOPXFWJqldwTF1O-ZZVCM4pLq4gAdUZ8xR4sk0LH-CNVqYVNXWjBgNpHKEuz0kKdQ1D1VcJfq0fH55hwsHa1msXwpHCOh-KZ_HHDADj4A_rQKWA2upc9wUsUeWlINi5k5iaiAWFYhMMKc8Hnrsxn9OaKjVUBW3sh0RTehfLeXnFHTfk0TF2CzcsJVyDgza160op5PHX0f6qL8mr9XR1qnN5TzeiaxSp7SHqmMYeEq-fEKElVK1ceDUQKjPDQrZatZRPfuMAAM6f0fqU4mBwiP6FV29avf7BTcSlEk6wemm9TG7sD1TjuCyp02us4GaVbjMum7GSHM5GUuYYDRiA2b0zc4DYO/download [following]\n",
      "--2022-11-21 17:06:34--  https://dl2.boxcloud.com/d/1/b1!YQgULKDM8oWKm58BK2YhkMIxaRccIY8LhufI_t57opZ3iV3uk5Fo3TdkNOwomjZium_KTvKbRn_iLLNt1lM4qVmyS-PqBfq7MGoV4W_vCkkDFqJvVO-nZ3O5agsEIlEyur_CP7bgBcYlkhhBmpxntLeJPJmXzZIbGbhrWqxTi59515k0tfePbBD3fLytm1CegAKYsPFSid7toosS2i9mvTDdCiwPD4gYLF_BCbBJS6b1tmSjYarPOVgxgp33_ilKNoZ7v5FFvYEP6Rnb8MXQKMa57m0oRYxoXk5ysOqA0FFcuaj-AAwVKy-UhWgtiXZ8rK0FxvIMgD3QB3J_aSTMOVg1Vt-wVoW77Y7mFRg2XIGGi-uROle6mYI4chAuks8RaEaYgPQ4eOWKVau5-kfO0Q2p3-k6-SQ0KdxGJdqjsh9TZjlx_z74K9gdtKMPY1NRiVz1CS_oC2YBnzeRCPIjuUR_ld_Fyon3CcUPPCXp9he2rA2TU3spoyFJW0sQO_0L8ekjCk2vxY6V6RwXGNfMKA6f4ZhWo4AxGkLZdtybQgs_0PrP-excjYLXKD9LoAyqe3VPGQkjAGWL0ZgD2arRxmZHhNQXEu1v84Zva1LIN52wmk-EvRygpJszVhAVToRceFL_nzD30uU3QRmP8v7PoTMxOx18VyrVSRReAIgdRWY23VcNaIOeYfmOE2TWrlhZQPEHrlM5HeMln7A_H7Rh-mXB4Ei4oSyesMlXxOABE4165aVFAxP2pGhZM22WgPQneUL85WxNtjMp5ZIZUIWuY5mFVf-bMsyasbhPnuLj10aTHcIY64J-wj7fyT4yFhuR_qZQlDal5Z6mRRTcV_nLJDfNzpc8MamG-U23VJhxM_Go4yvIldEnOOdhZSWX9TY1OMPAGolC5UR9M7AJoh4Ob80qug8ONKey8zm-9HjCv6eCajO1K9MT-mNl6U-jK5YPfnOZgEB2_ea31Ov4lw79zvgIMxqfidKsEiimM3g_wk0POOKcIHqDTTbv0kk8BCHvcnUn2mbsz4K38m-z7Qd4NOGcuP9Me-UcdRDP6uOWmdIbfYaSgOPXFWJqldwTF1O-ZZVCM4pLq4gAdUZ8xR4sk0LH-CNVqYVNXWjBgNpHKEuz0kKdQ1D1VcJfq0fH55hwsHa1msXwpHCOh-KZ_HHDADj4A_rQKWA2upc9wUsUeWlINi5k5iaiAWFYhMMKc8Hnrsxn9OaKjVUBW3sh0RTehfLeXnFHTfk0TF2CzcsJVyDgza160op5PHX0f6qL8mr9XR1qnN5TzeiaxSp7SHqmMYeEq-fEKElVK1ceDUQKjPDQrZatZRPfuMAAM6f0fqU4mBwiP6FV29avf7BTcSlEk6wemm9TG7sD1TjuCyp02us4GaVbjMum7GSHM5GUuYYDRiA2b0zc4DYO/download\n",
      "Resolving dl2.boxcloud.com (dl2.boxcloud.com)... 74.112.186.128\n",
      "Connecting to dl2.boxcloud.com (dl2.boxcloud.com)|74.112.186.128|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 238803811 (228M) [text/csv]\n",
      "Saving to: ‘training.1600000.processed.noemoticon.csv’\n",
      "\n",
      "training.1600000.pr 100%[===================>] 227.74M  21.3MB/s    in 12s     \n",
      "\n",
      "2022-11-21 17:06:46 (19.6 MB/s) - ‘training.1600000.processed.noemoticon.csv’ saved [238803811/238803811]\n",
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "m_cols = [\"target\", \"ids\", \"date\", \"flag\", \"user\", \"text\"]\n",
    "df_data = pd.read_csv(\"./training.1600000.processed.noemoticon.csv\", names=m_cols, encoding='latin-1')\n",
    "limited_data = False\n",
    "if limited_data:\n",
    "    count = 100000\n",
    "    neg_idx = 0\n",
    "    pos_idx = 800001\n",
    "    df = pd.concat([df_data[neg_idx:neg_idx + count], df_data[pos_idx:pos_idx + count]])\n",
    "else:\n",
    "    df = df_data\n",
    "data = df[[\"target\", \"text\"]]\n",
    "data = data[data[\"target\"] != 2]\n",
    "tweets = data[\"text\"].tolist()\n",
    "labels = data[\"target\"].tolist()"
   ],
   "metadata": {
    "id": "pB_SuGdHevlh"
   },
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "tweets = [str(tweet).lower().translate(str.maketrans('', '', string.punctuation)) for tweet in tweets]"
   ],
   "metadata": {
    "id": "La6ebGhHfUFO"
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from string import punctuation\n",
    "print(punctuation)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D7RdiQh6fUXd",
    "outputId": "64c46b56-67ae-45d7-c6d5-d18cfba930bf"
   },
   "execution_count": 6,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "all_tweets = ' '.join(tweets)\n",
    "# create a list of words\n",
    "words = all_tweets.split()\n",
    "# Count all the words using Counter Method\n",
    "count_words = Counter(words)\n",
    "\n",
    "total_words = len(words)\n",
    "sorted_words = count_words.most_common(total_words)\n",
    "print(count_words)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dua-BzfwfUnE",
    "outputId": "a8452ee2-8d33-4243-c12a-84d6f326b03c"
   },
   "execution_count": 7,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "print(count_words)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zdTm3OQdflVE",
    "outputId": "08ae55ca-5439-49eb-c340-c534397e8a79"
   },
   "execution_count": 8,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "UNK = 1\n",
    "vocab_to_int = {w: i + 2 for i, (w, c) in enumerate(sorted_words)}"
   ],
   "metadata": {
    "id": "I7NpY7f_fmal"
   },
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print (vocab_to_int)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0h1zqDpbfpfG",
    "outputId": "afa5e644-206d-4363-fc25-ecccde9c2f53"
   },
   "execution_count": 10,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "tweets_int = []\n",
    "for tweet in tweets:\n",
    "    r = [vocab_to_int[w] if w in vocab_to_int else 1 for w in tweet.split()]\n",
    "    tweets_int.append(r)\n",
    "print(tweets_int[0:3])\n",
    "encoded_labels = [1 if label == 4 else 0 for label in labels]"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uxHyIMAyfpv1",
    "outputId": "be60ddf3-0281-419c-89ba-01de5e231c6b"
   },
   "execution_count": 11,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[20177, 254587, 462, 103, 5, 1217, 8, 3540, 49, 874, 10240, 13, 1883, 32, 3, 41, 10, 447], [9, 781, 19, 108, 48, 543, 180, 547, 121, 2048, 10, 7, 285, 527, 78, 5, 2336, 146, 43, 262, 1198], [28049, 2, 110469, 310, 349, 11, 4, 1353, 1650, 3, 903, 1345, 4, 469, 39, 35, 13, 25889]]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "encoded_labels = [1 if label == 4 else 0 for label in labels]"
   ],
   "metadata": {
    "id": "kEv9y597fqCU"
   },
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# %matplotlib inline\n",
    "tweets_len = [len(x) for x in tweets_int]\n",
    "pd.Series(tweets_len).hist()\n",
    "plt.show()\n",
    "pd.Series(tweets_len).describe()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 586
    },
    "id": "6SUwWgoPgGO2",
    "outputId": "43385b0c-ac5c-4741-f0e4-83ecf1993fc6"
   },
   "execution_count": 13,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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\n"
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "count    1.600000e+06\n",
       "mean     1.303716e+01\n",
       "std      6.902189e+00\n",
       "min      1.000000e+00\n",
       "25%      7.000000e+00\n",
       "50%      1.200000e+01\n",
       "75%      1.800000e+01\n",
       "max      4.100000e+01\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "tweets_int = [tweets_int[i] for i, l in enumerate(tweets_len) if l > 0]\n",
    "encoded_labels = [encoded_labels[i] for i, l in enumerate(tweets_len) if l > 0]\n",
    "encoded_labels = np.array(encoded_labels)\n",
    "print(encoded_labels)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yq_fo0dJf0-s",
    "outputId": "add50f54-07f6-4e6e-b46c-abea2ab0d61d"
   },
   "execution_count": 14,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0 0 0 ... 1 1 1]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "def pad_features(tweets_int, seq_length):\n",
    "    \"\"\"\n",
    "    Return features of review_ints, where each tweet is padded with 0's or\n",
    "    truncated to the input seq_length.\n",
    "    \"\"\"\n",
    "    features = np.zeros((len(tweets_int), seq_length), dtype=int)\n",
    "    new = []\n",
    "    for i, tweet in enumerate(tweets_int):\n",
    "        tweet_len = len(tweet)\n",
    "\n",
    "        if tweet_len <= seq_length:\n",
    "            zeroes = list(np.zeros(seq_length - tweet_len))\n",
    "            new = zeroes + tweet\n",
    "        elif tweet_len > seq_length:\n",
    "            new = tweet[0:seq_length]\n",
    "\n",
    "        features[i, :] = np.array(new)\n",
    "\n",
    "    return features"
   ],
   "metadata": {
    "id": "xhLeUcqogNDW"
   },
   "execution_count": 15,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#batch_size = 50\n",
    "batch_size = 6000\n",
    "seq_length = 200\n",
    "drop_last = True"
   ],
   "metadata": {
    "id": "1Iqy8umFo97h"
   },
   "execution_count": 16,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "features = pad_features(tweets_int, seq_length)\n",
    "len_feat = len(features)\n",
    "print(features[:10, :])"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F8I0BKpipExg",
    "outputId": "e75a6174-d142-4be0-b532-a59cf5625696"
   },
   "execution_count": 17,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[     0      0      0 ...     41     10    447]\n",
      " [     0      0      0 ...     43    262   1198]\n",
      " [     0      0      0 ...     35     13  25889]\n",
      " ...\n",
      " [     0      0      0 ...     76    798      8]\n",
      " [     0      0      0 ...    114     18     10]\n",
      " [     0      0      0 ...   2504     16 254589]]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "2M8uo6BGpFFY"
   },
   "execution_count": 17,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "split_frac = 0.8\n",
    "train_x = features[0:int(split_frac * len_feat)]\n",
    "train_y = encoded_labels[0:int(split_frac * len_feat)]\n",
    "remaining_x = features[int(split_frac * len_feat):]\n",
    "remaining_y = encoded_labels[int(split_frac * len_feat):]\n",
    "valid_x = remaining_x[0:int(len(remaining_x) * 0.5)]\n",
    "valid_y = remaining_y[0:int(len(remaining_y) * 0.5)]\n",
    "test_x = remaining_x[int(len(remaining_x) * 0.5):]\n",
    "test_y = remaining_y[int(len(remaining_y) * 0.5):]"
   ],
   "metadata": {
    "id": "3kY3qRSagQ_A"
   },
   "execution_count": 18,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# create Tensor datasets\n",
    "train_data = TensorDataset(torch.from_numpy(train_x), torch.from_numpy(train_y))\n",
    "valid_data = TensorDataset(torch.from_numpy(valid_x), torch.from_numpy(valid_y))\n",
    "test_data = TensorDataset(torch.from_numpy(test_x), torch.from_numpy(test_y))"
   ],
   "metadata": {
    "id": "od6zT0UAgaqW"
   },
   "execution_count": 19,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# dataloaders\n",
    "# make sure to SHUFFLE your data\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size, drop_last=drop_last)\n",
    "valid_loader = DataLoader(valid_data, shuffle=True, batch_size=batch_size, drop_last=drop_last)\n",
    "test_loader = DataLoader(test_data, shuffle=True, batch_size=batch_size, drop_last=drop_last)"
   ],
   "metadata": {
    "id": "uOq3XBMNhaJw"
   },
   "execution_count": 20,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "dl6mXqj6hado"
   },
   "execution_count": 20,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# obtain one batch of training data\n",
    "dataiter = iter(train_loader)\n",
    "sample_x, sample_y = next(dataiter)\n",
    "print('Sample input size: ', sample_x.size())  # batch_size, seq_length\n",
    "print('Sample input: \\n', sample_x)\n",
    "print()\n",
    "print('Sample label size: ', sample_y.size())  # batch_size\n",
    "print('Sample label: \\n', sample_y)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uE5yv2KLha1Q",
    "outputId": "f8fb8abf-b6b5-45fb-c0a5-f936537106b0"
   },
   "execution_count": 21,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Sample input size:  torch.Size([5000, 200])\n",
      "Sample input: \n",
      " tensor([[    0,     0,     0,  ...,    16,   120,   106],\n",
      "        [    0,     0,     0,  ...,   128,     5,   325],\n",
      "        [    0,     0,     0,  ...,     3,  3452,    43],\n",
      "        ...,\n",
      "        [    0,     0,     0,  ...,     5,    30,    32],\n",
      "        [    0,     0,     0,  ...,   713,    10, 14258],\n",
      "        [    0,     0,     0,  ...,    16,    38,    83]])\n",
      "\n",
      "Sample label size:  torch.Size([5000])\n",
      "Sample label: \n",
      " tensor([0, 0, 0,  ..., 1, 1, 0])\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "6yiJXALJga_9"
   },
   "execution_count": 21,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ik-l-mrLVBJx"
   },
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "class SentimentLSTM(nn.Module):\n",
    "    \"\"\"\n",
    "    The RNN model that will be used to perform Sentiment analysis.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, vocab_size, output_size, embedding_dim, hidden_dim1,\n",
    "                 hidden_dim2, n_layers, drop_prob=0.5):\n",
    "        \"\"\"\n",
    "        Initialize the model by setting up the layers.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_dim1 = hidden_dim1\n",
    "        self.hidden_dim2 = hidden_dim2\n",
    "\n",
    "        # embedding and LSTM layers\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim1, n_layers,\n",
    "                            dropout=drop_prob, batch_first=True)\n",
    "\n",
    "        # dropout layer\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "        # FC linear and ReLU layers\n",
    "        self.fc1 = nn.Linear(hidden_dim1, hidden_dim2)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        # linear and sigmoid layers\n",
    "        self.fc2 = nn.Linear(hidden_dim2, output_size)\n",
    "        self.sig = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        \"\"\"\n",
    "        Perform a forward pass of our model on some input and hidden state.\n",
    "        \"\"\"\n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        # embeddings and lstm_out\n",
    "        embeds = self.embedding(x)\n",
    "        lstm_out, hidden = self.lstm(embeds, hidden)\n",
    "\n",
    "        # stack up lstm outputs\n",
    "        lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim1)\n",
    "\n",
    "        # dropout and fully-connected layer\n",
    "        out = self.dropout(lstm_out)\n",
    "        out = self.fc1(out)\n",
    "\n",
    "        # relu activation\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.fc2(out)\n",
    "        # sigmoid function\n",
    "        sig_out = self.sig(out)\n",
    "\n",
    "        # reshape to be batch_size first\n",
    "        sig_out = sig_out.view(batch_size, -1)\n",
    "        sig_out = sig_out[:, -1]  # get last batch of labels\n",
    "\n",
    "        # return last sigmoid output and hidden state\n",
    "        return sig_out, hidden\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        \"\"\" Initializes hidden state \"\"\"\n",
    "        # Create two new tensors with sizes n_layers x batch_size x hidden_dim,\n",
    "        # initialized to zero, for hidden state and cell state of LSTM\n",
    "        weight = next(self.parameters()).data\n",
    "        hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim1).zero_().to(device),\n",
    "                  weight.new(self.n_layers, batch_size, self.hidden_dim1).zero_().to(device))\n",
    "        return hidden"
   ],
   "metadata": {
    "id": "rwNxntFYw874"
   },
   "execution_count": 22,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Instantiate the model w/ hyperparams\n",
    "vocab_size = len(vocab_to_int) + 2  # +2 for the 0 padding, 1 UNKNOWN\n",
    "embedding_dim = 400\n",
    "hidden_dim1 = 256\n",
    "hidden_dim2 = 128\n",
    "output_size = 1\n",
    "n_layers = 2\n",
    "\n",
    "# training params\n",
    "lr = 0.001\n",
    "epochs = 4  # 3-4 is approx where I noticed the validation loss stop decreasing\n",
    "counter = 0\n",
    "print_every = 100\n",
    "clip = 5  # gradient clipping\n",
    "\n",
    "model = SentimentLSTM(vocab_size, output_size, embedding_dim, hidden_dim1, hidden_dim2, n_layers)\n",
    "print(model)\n",
    "\n",
    "# loss and optimization functions\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2jwN5L9oXqVj",
    "outputId": "128e18f6-64d9-446c-f407-64c2a88c46c1"
   },
   "execution_count": 23,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "SentimentLSTM(\n",
      "  (embedding): Embedding(850173, 400)\n",
      "  (lstm): LSTM(400, 256, num_layers=2, batch_first=True, dropout=0.5)\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      "  (fc1): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (fc2): Linear(in_features=128, out_features=1, bias=True)\n",
      "  (sig): Sigmoid()\n",
      ")\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# move model to GPU, if available\n",
    "model = model.to(device)\n",
    "\n",
    "valid_loss_min = np.Inf\n",
    "\n",
    "model.train()\n",
    "# train for some number of epochs\n",
    "for e in range(epochs):\n",
    "    # initialize hidden state\n",
    "    h = model.init_hidden(batch_size)\n",
    "\n",
    "    # batch loop\n",
    "    for inputs, labels in train_loader:\n",
    "        counter += 1\n",
    "\n",
    "        # Creating new variables for the hidden state, otherwise\n",
    "        # we'd backprop through the entire training history\n",
    "        h = tuple([each.data for each in h])\n",
    "\n",
    "        # zero accumulated gradients\n",
    "        model.zero_grad()\n",
    "\n",
    "        # get the output from the model\n",
    "        inputs = inputs.type(torch.LongTensor)\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        output, h = model(inputs, h)\n",
    "\n",
    "        # calculate the loss and perform backprop\n",
    "        loss = criterion(output.squeeze(), labels.float())\n",
    "        loss.backward()\n",
    "        # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "\n",
    "        # loss stats\n",
    "        if counter % print_every == 0:\n",
    "            # Get validation loss\n",
    "            val_h = model.init_hidden(batch_size)\n",
    "            val_losses = []\n",
    "            model.eval()\n",
    "            for inputs, labels in valid_loader:\n",
    "                # Creating new variables for the hidden state, otherwise\n",
    "                # we'd backprop through the entire training history\n",
    "                val_h = tuple([each.data for each in val_h])\n",
    "\n",
    "                inputs = inputs.type(torch.LongTensor)\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                output, val_h = model(inputs, val_h)\n",
    "                val_loss = criterion(output.squeeze(), labels.float())\n",
    "\n",
    "                val_losses.append(val_loss.item())\n",
    "\n",
    "            model.train()\n",
    "            print(\"Epoch: {}/{}...\".format(e + 1, epochs),\n",
    "                  \"Step: {}...\".format(counter),\n",
    "                  \"Loss: {:.6f}...\".format(loss.item()),\n",
    "                  \"Val Loss: {:.6f}\".format(np.mean(val_losses)))\n",
    "            if np.mean(val_losses) <= valid_loss_min:\n",
    "                torch.save(model.state_dict(), './lstm_state_dict.pt')\n",
    "                print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(valid_loss_min,np.mean(val_losses)))\n",
    "                valid_loss_min = np.mean(val_losses)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vRJrG6GgXrAS",
    "outputId": "2134014d-7600-4919-d7bb-b1d513b57f63"
   },
   "execution_count": 24,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch: 1/4... Step: 100... Loss: 0.436668... Val Loss: 0.691436\n",
      "Validation loss decreased (inf --> 0.691436).  Saving model ...\n",
      "Epoch: 1/4... Step: 200... Loss: 0.397160... Val Loss: 0.645828\n",
      "Validation loss decreased (0.691436 --> 0.645828).  Saving model ...\n",
      "Epoch: 2/4... Step: 300... Loss: 0.376070... Val Loss: 0.593196\n",
      "Validation loss decreased (0.645828 --> 0.593196).  Saving model ...\n",
      "Epoch: 2/4... Step: 400... Loss: 0.363025... Val Loss: 0.555839\n",
      "Validation loss decreased (0.593196 --> 0.555839).  Saving model ...\n",
      "Epoch: 2/4... Step: 500... Loss: 0.348109... Val Loss: 0.563711\n",
      "Epoch: 3/4... Step: 600... Loss: 0.329400... Val Loss: 0.563726\n",
      "Epoch: 3/4... Step: 700... Loss: 0.325752... Val Loss: 0.508574\n",
      "Validation loss decreased (0.555839 --> 0.508574).  Saving model ...\n",
      "Epoch: 4/4... Step: 800... Loss: 0.288925... Val Loss: 0.688716\n",
      "Epoch: 4/4... Step: 900... Loss: 0.271377... Val Loss: 0.685350\n",
      "Epoch: 4/4... Step: 1000... Loss: 0.288123... Val Loss: 0.630765\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "def print_data_accuracy(model, data_loader, data_type='Test'):\n",
    "    # Get test data loss and accuracy\n",
    "    data_losses = []  # track loss\n",
    "    num_correct = 0\n",
    "\n",
    "    # init hidden state\n",
    "    h = model.init_hidden(batch_size)\n",
    "\n",
    "    model.eval()\n",
    "    # iterate over test data\n",
    "    for inputs, labels in data_loader:\n",
    "        # Creating new variables for the hidden state, otherwise\n",
    "        # we'd backprop through the entire training history\n",
    "        h = tuple([each.data for each in h])\n",
    "\n",
    "        # get predicted outputs\n",
    "        inputs = inputs.type(torch.LongTensor)\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        output, h = model(inputs, h)\n",
    "\n",
    "        # calculate loss\n",
    "        data_loss = criterion(output.squeeze(), labels.float())\n",
    "        data_losses.append(data_loss.item())\n",
    "\n",
    "        # convert output probabilities to predicted class (0 or 1)\n",
    "        pred = torch.round(output.squeeze())  # rounds to the nearest integer\n",
    "\n",
    "        # compare predictions to true label\n",
    "        correct_tensor = pred.eq(labels.float().view_as(pred))\n",
    "        correct = np.squeeze(correct_tensor.detach().cpu().numpy())\n",
    "        num_correct += np.sum(correct)\n",
    "\n",
    "    # -- stats! -- ##\n",
    "    # avg data loss\n",
    "    print(f\"{data_type} loss: {np.mean(data_losses):.3f}\")\n",
    "\n",
    "    # accuracy over all the data\n",
    "    data_acc = num_correct / len(data_loader.dataset)\n",
    "    print(f\"{data_type} accuracy: {data_acc:.3f}\")\n",
    "    print()"
   ],
   "metadata": {
    "id": "ME7IXKrWiGrf"
   },
   "execution_count": 25,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Loading the best model\n",
    "model.load_state_dict(torch.load('./lstm_state_dict.pt'))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-WibDGOepjqu",
    "outputId": "4ec46fe6-4113-4efc-8bd7-4eeca6258804"
   },
   "execution_count": 26,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "print(f\"\\nLSTM - Twitter 1,600,000 Data Accuracies: \")\n",
    "print_data_accuracy(model, train_loader, data_type=\"Train\")\n",
    "print_data_accuracy(model, valid_loader, data_type=\"Valid\")\n",
    "print_data_accuracy(model, test_loader, data_type=\"Test\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f5PdNiBviQrf",
    "outputId": "00895f43-ebfb-49cb-d1b7-ee78129a5be3"
   },
   "execution_count": 27,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "LSTM - Twitter 1,600,000 Data Accuracies: \n",
      "Train loss: 0.288\n",
      "Train accuracy: 0.880\n",
      "\n",
      "Valid loss: 0.509\n",
      "Valid accuracy: 0.763\n",
      "\n",
      "Test loss: 0.537\n",
      "Test accuracy: 0.752\n",
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "s4TVQPVoiYFv"
   },
   "execution_count": 27,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# GRU"
   ],
   "metadata": {
    "id": "T4zqs6Mjw-ep"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class SentimentGRU(nn.Module):\n",
    "    \"\"\"\n",
    "    The RNN model that will be used to perform Sentiment analysis.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, vocab_size, output_size, embedding_dim, hidden_dim1,\n",
    "                 hidden_dim2, n_layers, drop_prob=0.5):\n",
    "        \"\"\"\n",
    "        Initialize the model by setting up the layers.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_dim1 = hidden_dim1\n",
    "        self.hidden_dim2 = hidden_dim2\n",
    "\n",
    "        # embedding and GRU layers\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = nn.GRU(embedding_dim, hidden_dim1, n_layers,\n",
    "                            dropout=drop_prob, batch_first=True)\n",
    "\n",
    "        # dropout layer\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "        # FC linear and ReLU layers\n",
    "        self.fc1 = nn.Linear(hidden_dim1, hidden_dim2)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        # linear and sigmoid layers\n",
    "        self.fc2 = nn.Linear(hidden_dim2, output_size)\n",
    "        self.sig = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        \"\"\"\n",
    "        Perform a forward pass of our model on some input and hidden state.\n",
    "        \"\"\"\n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        # embeddings and gru_out\n",
    "        embeds = self.embedding(x)\n",
    "        gru_out, hidden = self.gru(embeds, hidden)\n",
    "\n",
    "        # stack up gru outputs\n",
    "        gru_out = gru_out.contiguous().view(-1, self.hidden_dim1)\n",
    "\n",
    "        # dropout and fully-connected layer\n",
    "        out = self.dropout(gru_out)\n",
    "        out = self.fc1(out)\n",
    "\n",
    "        # relu activation\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.fc2(out)\n",
    "        # sigmoid function\n",
    "        sig_out = self.sig(out)\n",
    "\n",
    "        # reshape to be batch_size first\n",
    "        sig_out = sig_out.view(batch_size, -1)\n",
    "        sig_out = sig_out[:, -1]  # get last batch of labels\n",
    "\n",
    "        # return last sigmoid output and hidden state\n",
    "        return sig_out, hidden\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        \"\"\" Initializes hidden state \"\"\"\n",
    "        # Create two new tensors with sizes n_layers x batch_size x hidden_dim,\n",
    "        # initialized to zero, for hidden state and cell state of GRU\n",
    "        weight = next(self.parameters()).data\n",
    "        hidden = weight.new(self.n_layers, batch_size, self.hidden_dim1).zero_().to(device)\n",
    "        return hidden"
   ],
   "metadata": {
    "id": "BbBmPhrDw_07"
   },
   "execution_count": 28,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Instantiate the model w/ hyperparams\n",
    "vocab_size = len(vocab_to_int) + 2  # +2 for the 0 padding, 1 UNKNOWN\n",
    "embedding_dim = 400\n",
    "hidden_dim1 = 256\n",
    "hidden_dim2 = 128\n",
    "output_size = 1\n",
    "n_layers = 2\n",
    "\n",
    "# training params\n",
    "lr = 0.001\n",
    "epochs = 4  # 3-4 is approx where I noticed the validation loss stop decreasing\n",
    "counter = 0\n",
    "print_every = 100\n",
    "clip = 5  # gradient clipping\n",
    "\n",
    "model = SentimentGRU(vocab_size, output_size, embedding_dim, hidden_dim1, hidden_dim2, n_layers)\n",
    "print(model)\n",
    "\n",
    "# loss and optimization functions\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zJpVv0U1q3Z6",
    "outputId": "20d39fa3-6469-41ca-94f7-203f664652e3"
   },
   "execution_count": 29,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "SentimentGRU(\n",
      "  (embedding): Embedding(850173, 400)\n",
      "  (gru): GRU(400, 256, num_layers=2, batch_first=True, dropout=0.5)\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      "  (fc1): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (fc2): Linear(in_features=128, out_features=1, bias=True)\n",
      "  (sig): Sigmoid()\n",
      ")\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# move model to GPU, if available\n",
    "model = model.to(device)\n",
    "\n",
    "valid_loss_min = np.Inf\n",
    "\n",
    "model.train()\n",
    "# train for some number of epochs\n",
    "for e in range(epochs):\n",
    "    # initialize hidden state\n",
    "    h = model.init_hidden(batch_size)\n",
    "\n",
    "    # batch loop\n",
    "    for inputs, labels in train_loader:\n",
    "        counter += 1\n",
    "\n",
    "        # Creating new variables for the hidden state, otherwise\n",
    "        # we'd backprop through the entire training history\n",
    "        # h = tuple([each.data for each in h])\n",
    "        h = h.data\n",
    "\n",
    "        inputs = inputs.type(torch.LongTensor)\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # zero accumulated gradients\n",
    "        model.zero_grad()\n",
    "\n",
    "        # get the output from the model\n",
    "        output, h = model(inputs, h)\n",
    "\n",
    "        # calculate the loss and perform backprop\n",
    "        loss = criterion(output.squeeze(), labels.float())\n",
    "        loss.backward()\n",
    "        # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "\n",
    "        # loss stats\n",
    "        if counter % print_every == 0:\n",
    "            # Get validation loss\n",
    "            val_h = model.init_hidden(batch_size)\n",
    "            val_losses = []\n",
    "            model.eval()\n",
    "            for inputs, labels in valid_loader:\n",
    "                # Creating new variables for the hidden state, otherwise\n",
    "                # we'd backprop through the entire training history\n",
    "                val_h = val_h.data\n",
    "\n",
    "                inputs = inputs.type(torch.LongTensor)\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                output, val_h = model(inputs, val_h)\n",
    "\n",
    "                val_loss = criterion(output.squeeze(), labels.float())\n",
    "                val_losses.append(val_loss.item())\n",
    "\n",
    "            model.train()\n",
    "            print(\"Epoch: {}/{}...\".format(e + 1, epochs),\n",
    "                  \"Step: {}...\".format(counter),\n",
    "                  \"Loss: {:.6f}...\".format(loss.item()),\n",
    "                  \"Val Loss: {:.6f}\".format(np.mean(val_losses)))\n",
    "            \n",
    "            if np.mean(val_losses) <= valid_loss_min:\n",
    "                torch.save(model.state_dict(), './gru_state_dict.pt')\n",
    "                print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(valid_loss_min,np.mean(val_losses)))\n",
    "                valid_loss_min = np.mean(val_losses)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bjN0R1qtq4Hf",
    "outputId": "2c3ecab5-6756-4fe9-e681-d7939abf3119"
   },
   "execution_count": 30,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch: 1/4... Step: 100... Loss: 0.441532... Val Loss: 0.711466\n",
      "Validation loss decreased (inf --> 0.711466).  Saving model ...\n",
      "Epoch: 1/4... Step: 200... Loss: 0.406568... Val Loss: 0.616920\n",
      "Validation loss decreased (0.711466 --> 0.616920).  Saving model ...\n",
      "Epoch: 2/4... Step: 300... Loss: 0.367989... Val Loss: 0.522253\n",
      "Validation loss decreased (0.616920 --> 0.522253).  Saving model ...\n",
      "Epoch: 2/4... Step: 400... Loss: 0.359478... Val Loss: 0.563472\n",
      "Epoch: 2/4... Step: 500... Loss: 0.367941... Val Loss: 0.580040\n",
      "Epoch: 3/4... Step: 600... Loss: 0.325200... Val Loss: 0.592292\n",
      "Epoch: 3/4... Step: 700... Loss: 0.351810... Val Loss: 0.595815\n",
      "Epoch: 4/4... Step: 800... Loss: 0.276123... Val Loss: 0.597794\n",
      "Epoch: 4/4... Step: 900... Loss: 0.278023... Val Loss: 0.679470\n",
      "Epoch: 4/4... Step: 1000... Loss: 0.280708... Val Loss: 0.603732\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Loading the best model GRU\n",
    "model.load_state_dict(torch.load('./gru_state_dict.pt'))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mjh_mRhU9Lmi",
    "outputId": "673117bc-2273-491d-9d78-7880da0f491d"
   },
   "execution_count": 31,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "metadata": {},
     "execution_count": 31
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "def print_data_accuracy(model, data_loader, data_type='Test'):\n",
    "    # Get test data loss and accuracy\n",
    "    data_losses = []  # track loss\n",
    "    num_correct = 0\n",
    "\n",
    "    # init hidden state\n",
    "    h = model.init_hidden(batch_size)\n",
    "\n",
    "    model.eval()\n",
    "    # iterate over test data\n",
    "    for inputs, labels in data_loader:\n",
    "        # Creating new variables for the hidden state, otherwise\n",
    "        # we'd backprop through the entire training history\n",
    "        h = h.data\n",
    "\n",
    "        # get predicted outputs\n",
    "        inputs = inputs.type(torch.LongTensor)\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        output, h = model(inputs, h)\n",
    "\n",
    "        # calculate loss\n",
    "        data_loss = criterion(output.squeeze(), labels.float())\n",
    "        data_losses.append(data_loss.item())\n",
    "\n",
    "        # convert output probabilities to predicted class (0 or 1)\n",
    "        pred = torch.round(output.squeeze())  # rounds to the nearest integer\n",
    "\n",
    "        # compare predictions to true label\n",
    "        correct_tensor = pred.eq(labels.float().view_as(pred))\n",
    "        correct = np.squeeze(correct_tensor.detach().cpu().numpy())\n",
    "        num_correct += np.sum(correct)\n",
    "\n",
    "    # -- stats! -- ##\n",
    "    # avg data loss\n",
    "    print(f\"{data_type} loss: {np.mean(data_losses):.3f}\")\n",
    "\n",
    "    # accuracy over all the data\n",
    "    data_acc = num_correct / len(data_loader.dataset)\n",
    "    print(f\"{data_type} accuracy: {data_acc:.3f}\")\n",
    "    print()"
   ],
   "metadata": {
    "id": "EDRB8oja9VzJ"
   },
   "execution_count": 32,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print(f\"\\nGRU - Twitter 1,600,000 Data Accuracies: \")\n",
    "print_data_accuracy(model, train_loader, data_type=\"Train\")\n",
    "print_data_accuracy(model, valid_loader, data_type=\"Valid\")\n",
    "print_data_accuracy(model, test_loader, data_type=\"Test\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1s-92Iuxq4Xv",
    "outputId": "c158b2a2-aa0e-4e95-8497-434ad4db5d98"
   },
   "execution_count": 33,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "GRU - Twitter 1,600,000 Data Accuracies: \n",
      "Train loss: 0.367\n",
      "Train accuracy: 0.838\n",
      "\n",
      "Valid loss: 0.522\n",
      "Valid accuracy: 0.737\n",
      "\n",
      "Test loss: 0.539\n",
      "Test accuracy: 0.727\n",
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "uIa7AueSq4nD"
   },
   "execution_count": 33,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Sample Test Tokenizer and Features"
   ],
   "metadata": {
    "id": "T007EAWqrMeM"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def tokenize_review(test_review):\n",
    "    test_review = test_review.lower()  # lowercase\n",
    "    # get rid of punctuation\n",
    "    test_text = ''.join([c for c in test_review if c not in punctuation])\n",
    "\n",
    "    # splitting by spaces\n",
    "    test_words = test_text.split()\n",
    "\n",
    "    # tokens\n",
    "    test_ints = []\n",
    "    test_ints.append([vocab_to_int[word] if word in vocab_to_int else 1 for word in test_words])\n",
    "\n",
    "    return test_ints\n",
    "\n",
    "\n",
    "def predict(net, test_review, sequence_length=200):\n",
    "    net.eval()\n",
    "\n",
    "    # tokenize review\n",
    "    test_ints = tokenize_review(test_review)\n",
    "\n",
    "    # pad tokenized sequence\n",
    "    seq_length = sequence_length\n",
    "    features = pad_features(test_ints, seq_length)\n",
    "\n",
    "    # convert to tensor to pass into your model\n",
    "    feature_tensor = torch.from_numpy(features)\n",
    "\n",
    "    batch_size = feature_tensor.size(0)\n",
    "\n",
    "    # initialize hidden state\n",
    "    h = net.init_hidden(batch_size)\n",
    "\n",
    "    feature_tensor = feature_tensor.to(device)\n",
    "\n",
    "    # get the output from the model\n",
    "    output, h = net(feature_tensor, h)\n",
    "\n",
    "    # convert output probabilities to predicted class (0 or 1)\n",
    "    pred = torch.round(output.squeeze())\n",
    "    # printing output value, before rounding\n",
    "    print('Prediction value, pre-rounding: {:.6f}'.format(output.item()))\n",
    "\n",
    "    # print custom response\n",
    "    if pred.item() == 1:\n",
    "        print(\"Positive review detected!\")\n",
    "    else:\n",
    "        print(\"Negative review detected.\")\n",
    "\n",
    "\n",
    "test_review = 'This movie had the best acting and the dialogue was so good. I loved it.'\n",
    "seq_length = 200  # good to use the length that was trained on\n",
    "predict(model, test_review, seq_length)\n",
    "\n",
    "# test code and generate tokenized review\n",
    "test_ints = tokenize_review(test_review)\n",
    "print(test_ints)\n",
    "\n",
    "# test sequence padding\n",
    "seq_length = 200\n",
    "features = pad_features(test_ints, seq_length)\n",
    "\n",
    "print(features)\n",
    "\n",
    "# test conversion to tensor and pass into your model\n",
    "feature_tensor = torch.from_numpy(features)\n",
    "print(feature_tensor.size())"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-dqTKiHlq45D",
    "outputId": "46878cec-f3f1-4797-8662-104c2c9969dd"
   },
   "execution_count": 34,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Prediction value, pre-rounding: 0.982435\n",
      "Positive review detected!\n",
      "[[28, 218, 63, 4, 169, 1881, 7, 4, 12507, 27, 17, 30, 2, 522, 10]]\n",
      "[[    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0    28   218    63     4   169  1881     7\n",
      "      4 12507    27    17    30     2   522    10]]\n",
      "torch.Size([1, 200])\n"
     ]
    }
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "collapsed_sections": [
    "T007EAWqrMeM"
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU",
  "gpuClass": "standard"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
